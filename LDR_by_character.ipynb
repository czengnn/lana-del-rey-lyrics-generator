{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDR_by_character.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YsCFde9O7H5v6sAu9Eu1oIdFbLEoiMel",
      "authorship_tag": "ABX9TyNN5gAw8QoDLlmwaxtZn747",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czengnn/lana-del-rey-lyrics-generator/blob/main/LDR_by_character.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffVU7m5uq9cW"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import re \n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neEO7YMGrLXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c11c13c-a336-4fa7-8654-7a1c9a3b09ef"
      },
      "source": [
        "# load songs\n",
        "songs1 = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_83.csv').drop('Unnamed: 0', axis=1)\n",
        "songs2 = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_15.csv').drop('Unnamed: 0', axis=1)\n",
        "songs = pd.concat([songs1, songs2], axis=0)\n",
        "songs.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzGQ7sSrgo5",
        "outputId": "54117dba-ace3-4463-a5dd-a5d5eeccca6a"
      },
      "source": [
        "# test revoming text with brackets around them\n",
        "test_text = songs2.lyrics[0][:50]\n",
        "print(test_text)\n",
        "print(re.sub(r'\\[[^][]*\\]', '', test_text))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Verse 1]\n",
            "Sun stare, don't care with my head in my\n",
            "\n",
            "Sun stare, don't care with my head in my\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Dwmg6gq4mT"
      },
      "source": [
        "# put lyrics into 1 string\n",
        "text = ''\n",
        "for song in songs['lyrics']:\n",
        "    text = text + song.lower()\n",
        "    \n",
        "# remove the text with brackets around them, such as [Verse 1]\n",
        "text = re.sub(r'\\[[^][]*\\]', '', text)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUQrFdYC2hNo",
        "outputId": "83c0bde1-47dd-4b82-a9e3-69d27135b9cd"
      },
      "source": [
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 161722 characters\n",
            "61 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP0meFb05Bq5",
        "outputId": "553639b6-dd03-4023-fc4d-ca268a9051d6"
      },
      "source": [
        "# taking a look at the first 300 characters\n",
        "print(text[:300])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "why? (\"got that?\")\n",
            "who, me? (\"louder!\")\n",
            "why? (\"got that?\")\n",
            "\n",
            "\n",
            "feet don't fail me now\n",
            "take me to the finish line\n",
            "oh, my heart, it breaks every step that i take\n",
            "but i'm hoping at the gates, they'll tell me that you're mine\n",
            "walking through the city streets, is it by mistake or design?\n",
            "i feel so alone o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMFAEfC_3z2S"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab))\n",
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True)\n",
        "\n",
        "# join the characters back into strings\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir9bvs-Ar391",
        "outputId": "2eec3447-357a-4f19-b3de-9040d11589f9"
      },
      "source": [
        "# Create training examples and targets\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(161722,), dtype=int64, numpy=array([ 2, 45, 30, ..., 37, 44, 27])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdk6Vgw6s64W"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLS3KIv5s9_f"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59VB-A_Ks99D",
        "outputId": "865f8eab-8f60-400c-963d-0ee75de72d6d"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\nwhy? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the f'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nyLBiBbs96e"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtD4OyiIs939",
        "outputId": "7d000c68-6f9e-4e9b-ea28-3b98432bfc09"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auxaRHL9s91R",
        "outputId": "09d5a5a9-24db-4644-a21a-0b4ceacb1517"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'\\nwhy? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the '\n",
            "Target: b'why? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the f'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaRCG0iJtSSM"
      },
      "source": [
        "### Create training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOLJ01y5s9yx",
        "outputId": "72a25d66-6997-4624-e11b-8b44b4926a2e"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlSLRqFHtYTp"
      },
      "source": [
        "### Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaM_TY9Ks9t2"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 512"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ARhng_zu32M"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = Embedding(vocab_size, #61\n",
        "                                   embedding_dim, #256\n",
        "                                   batch_input_shape=[BATCH_SIZE, None]) #64\n",
        "        self.LSTM_1 = Bidirectional(LSTM(rnn_units, #512\n",
        "                           return_sequences=True,\n",
        "                           stateful=True))\n",
        "        self.Dropout_1 = Dropout(0.2)        \n",
        "        self.LSTM_2 = LSTM(rnn_units, #512\n",
        "                           return_sequences=True, \n",
        "                           stateful=True)\n",
        "        self.Dropout_2 = Dropout(0.2) \n",
        "        self.dense_1 = Dense(vocab_size/2, activation='relu')\n",
        "        self.dense_2 = Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        x = self.LSTM_1(x, training=training)\n",
        "        x = self.Dropout_1(x, training=training)\n",
        "        x = self.LSTM_2(x, training=training)\n",
        "        x = self.Dropout_2(x, training=training)\n",
        "        x = self.dense_1(x, training=training)\n",
        "        x = self.dense_2(x, training=training)\n",
        "        return x\n",
        "# ValueError: Input 0 is incompatible with layer forward_lstm_51: \n",
        "# expected shape=(64, None, 256), found shape=(1, None, 256)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uSjmyuYtbNK"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig1YIARItbKV",
        "outputId": "37c1a257-4899-44de-a839-6f77b7f852e7"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 63) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dig380GBtbH7",
        "outputId": "340f9e40-9a3d-48aa-82a2-ff9c8b5c9074"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  16128     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional multiple                  3149824   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  3147776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  15903     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  2016      \n",
            "=================================================================\n",
            "Total params: 6,331,647\n",
            "Trainable params: 6,331,647\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YTzIvLMFHur"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbkrrgOltbFW"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgpKZmNtbCs",
        "outputId": "3a92dcb2-a9f5-4f3c-8c2b-a1c947b4f706"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "EPOCHS = 3\n",
        "\n",
        "history = model.fit(dataset, \n",
        "                    epochs=EPOCHS, \n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Save the weights\n",
        "model.save_weights('/content/drive/MyDrive/data/models/ldr_by_char/ldr_by_char')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "25/25 [==============================] - 215s 8s/step - loss: 3.8014\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 212s 8s/step - loss: 3.1107\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 211s 8s/step - loss: 2.3320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0QpmA0Sd5j2"
      },
      "source": [
        "# Create a new model instance\n",
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "model.load_weights('/content/drive/MyDrive/data/models/ldr_by_char/ldr_by_char')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKedZbWGUPPU",
        "outputId": "4f258e1a-2131-4de2-f228-8d9aedee3763"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sSpK-n2nTUpI",
        "outputId": "bd288a63-9bf1-4029-90a5-5bea91c97e12"
      },
      "source": [
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra9O9qrKlLMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ymNiDrXkM4k"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBclSLlbVnH1"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    # skip_ids = self.ids_from_chars(['', '[UNK]'])[:, None]\n",
        "    # sparse_mask = tf.SparseTensor(\n",
        "    #     # Put a -inf at each bad index.\n",
        "    #     values=[-float('inf')]*len(skip_ids),\n",
        "    #     indices=skip_ids,\n",
        "    #     # Match the shape to the vocabulary\n",
        "    #     dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    # self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hK9QUQWEaz"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "76jmkfxSWhtx",
        "outputId": "f44c76c5-00ee-4484-cdea-9ca4cf685459"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['james dean'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-47c582e8f3de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3885\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-24-bbd17e2a7355>:27 generate_one_step  *\n        predicted_logits, states = self.model(inputs=input_ids, states=states,\n    <ipython-input-27-3e7f9158334a>:21 call  *\n        x = self.LSTM_1(x, training=training)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:539 __call__  **\n        return super(Bidirectional, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:653 call\n        initial_state=forward_state, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer forward_lstm: expected shape=(64, None, 256), found shape=(1, None, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpEpmgiGekPu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}