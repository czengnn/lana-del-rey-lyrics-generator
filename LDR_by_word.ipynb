{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDR_by_word.ipynb",
      "provenance": [],
      "mount_file_id": "1wyacN2Z1_YP6yW7MyXJHLxpMK7D1vPrh",
      "authorship_tag": "ABX9TyMN2uxiGVvfn6EheQ9K1/lX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czengnn/lana-del-rey-lyrics-generator/blob/main/LDR_by_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlWo3BTR3CTP"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import re \n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MesZiJjU3SCh",
        "outputId": "cbc1cbb3-5661-4690-a541-25c7b9483ede"
      },
      "source": [
        "# load songs\n",
        "songs = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_83.csv').drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# put lyrics into 1 string\n",
        "text = ''\n",
        "for song in songs['lyrics']:\n",
        "  text = text + song.lower()\n",
        "\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 143660 characters\n",
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AplgShWA3jeS",
        "outputId": "8809886f-7bff-48d1-af1a-1b84a5286fd5"
      },
      "source": [
        "text.split('\\n')[:10]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[intro: lana del rey + sample]',\n",
              " 'why? (\"got that?\")',\n",
              " 'who, me? (\"louder!\")',\n",
              " 'why? (\"got that?\")',\n",
              " '',\n",
              " '[verse 1]',\n",
              " \"feet don't fail me now\",\n",
              " 'take me to the finish line',\n",
              " 'oh, my heart, it breaks every step that i take',\n",
              " \"but i'm hoping at the gates, they'll tell me that you're mine\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3b20asj3SRr"
      },
      "source": [
        "corpus = list(set(text.split('\\n')))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp--rn6031rr"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Mv1ekh4d41"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tb0nJE54nbc",
        "outputId": "8401274e-47d4-4cba-ad1b-d09853075bac"
      },
      "source": [
        "input_sequences[:5]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[246, 301],\n",
              " [246, 301, 70],\n",
              " [246, 301, 70, 875],\n",
              " [246, 301, 70, 875, 1],\n",
              " [246, 301, 70, 875, 1, 206]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7r1sw3m40Lp"
      },
      "source": [
        "# pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences,\n",
        "                                         maxlen = max_sequence_len, padding='pre'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c6G0ifE5W8-",
        "outputId": "90cf07a4-eff1-4b29-e903-814c9377c44a"
      },
      "source": [
        "input_sequences[:5]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 246, 301],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 246, 301,  70],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 246, 301,  70, 875],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        246, 301,  70, 875,   1],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 246,\n",
              "        301,  70, 875,   1, 206]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJUFvZ3v5jeK"
      },
      "source": [
        "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGniSvLy5pOw"
      },
      "source": [
        "### Building The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ9xj1TQ5mYs",
        "outputId": "fd5ce6d2-478e-42e7-9d45-bc539c6ae1d0"
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n",
        "vocab_size = total_words\n",
        "embed_dim = 50\n",
        "def create_model(vocab_size, embed_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim, input_length=max_sequence_len-1))\n",
        "    # Add an LSTM Layer\n",
        "    model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "    # A dropout layer for regularisation\n",
        "    model.add(Dropout(0.2))\n",
        "    # Add another LSTM Layer\n",
        "    model.add(LSTM(100,return_sequences=False)) \n",
        "    model.add(Dense(vocab_size//2, activation='relu'))\n",
        "    # In the last layer, the shape should be equal to the total number of words present in our corpus\n",
        "    model.add(Dense(vocab_size, activation='softmax'))\n",
        "    model.compile(loss=sparse_cat_loss, optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
        "    return model\n",
        "print(model.summary())\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 17, 50)            121000    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 17, 300)           241200    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1210)              122210    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2420)              2930620   \n",
            "=================================================================\n",
            "Total params: 3,575,430\n",
            "Trainable params: 3,575,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUS1h2h_53su",
        "outputId": "e61d9de2-6176-4bcf-9d0c-a328e34877af"
      },
      "source": [
        "history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "497/497 [==============================] - 62s 113ms/step - loss: 6.5682 - accuracy: 0.0360\n",
            "Epoch 2/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 5.9237 - accuracy: 0.0370\n",
            "Epoch 3/100\n",
            "497/497 [==============================] - 58s 117ms/step - loss: 5.6952 - accuracy: 0.0394\n",
            "Epoch 4/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 5.5221 - accuracy: 0.0532\n",
            "Epoch 5/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 5.3240 - accuracy: 0.0684\n",
            "Epoch 6/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 5.1168 - accuracy: 0.0889\n",
            "Epoch 7/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 4.9135 - accuracy: 0.1033\n",
            "Epoch 8/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 4.7251 - accuracy: 0.1210\n",
            "Epoch 9/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 4.5724 - accuracy: 0.1317\n",
            "Epoch 10/100\n",
            "497/497 [==============================] - 56s 114ms/step - loss: 4.4150 - accuracy: 0.1376\n",
            "Epoch 11/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 4.2614 - accuracy: 0.1521\n",
            "Epoch 12/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 4.1304 - accuracy: 0.1609\n",
            "Epoch 13/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.9976 - accuracy: 0.1758\n",
            "Epoch 14/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.8573 - accuracy: 0.1846\n",
            "Epoch 15/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.7178 - accuracy: 0.2024\n",
            "Epoch 16/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.5552 - accuracy: 0.2214\n",
            "Epoch 17/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.4054 - accuracy: 0.2327\n",
            "Epoch 18/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.2774 - accuracy: 0.2562\n",
            "Epoch 19/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 3.1321 - accuracy: 0.2748\n",
            "Epoch 20/100\n",
            "497/497 [==============================] - 55s 112ms/step - loss: 3.0090 - accuracy: 0.2962\n",
            "Epoch 21/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 2.8897 - accuracy: 0.3159\n",
            "Epoch 22/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 2.7525 - accuracy: 0.3355\n",
            "Epoch 23/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 2.6484 - accuracy: 0.3556\n",
            "Epoch 24/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 2.5284 - accuracy: 0.3829\n",
            "Epoch 25/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 2.4039 - accuracy: 0.4014\n",
            "Epoch 26/100\n",
            "497/497 [==============================] - 55s 111ms/step - loss: 2.3234 - accuracy: 0.4181\n",
            "Epoch 27/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 2.2327 - accuracy: 0.4302\n",
            "Epoch 28/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 2.1072 - accuracy: 0.4570\n",
            "Epoch 29/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 2.0110 - accuracy: 0.4817\n",
            "Epoch 30/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 1.9565 - accuracy: 0.4905\n",
            "Epoch 31/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 1.8811 - accuracy: 0.5019\n",
            "Epoch 32/100\n",
            "497/497 [==============================] - 56s 112ms/step - loss: 1.8017 - accuracy: 0.5285\n",
            "Epoch 33/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.7168 - accuracy: 0.5451\n",
            "Epoch 34/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.6506 - accuracy: 0.5618\n",
            "Epoch 35/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.6120 - accuracy: 0.5662\n",
            "Epoch 36/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.5494 - accuracy: 0.5851\n",
            "Epoch 37/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.4873 - accuracy: 0.5984\n",
            "Epoch 38/100\n",
            "497/497 [==============================] - 55s 112ms/step - loss: 1.4285 - accuracy: 0.6123\n",
            "Epoch 39/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.3626 - accuracy: 0.6304\n",
            "Epoch 40/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.3438 - accuracy: 0.6328\n",
            "Epoch 41/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.2943 - accuracy: 0.6456\n",
            "Epoch 42/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.2275 - accuracy: 0.6638\n",
            "Epoch 43/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 1.2298 - accuracy: 0.6616\n",
            "Epoch 44/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.1502 - accuracy: 0.6820\n",
            "Epoch 45/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 1.1481 - accuracy: 0.6852\n",
            "Epoch 46/100\n",
            "497/497 [==============================] - 58s 116ms/step - loss: 1.1045 - accuracy: 0.6901\n",
            "Epoch 47/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.0739 - accuracy: 0.7011\n",
            "Epoch 48/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 1.0437 - accuracy: 0.7107\n",
            "Epoch 49/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 0.9969 - accuracy: 0.7238\n",
            "Epoch 50/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 1.0071 - accuracy: 0.7187\n",
            "Epoch 51/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.9568 - accuracy: 0.7338\n",
            "Epoch 52/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.9250 - accuracy: 0.7378\n",
            "Epoch 53/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 0.9119 - accuracy: 0.7413\n",
            "Epoch 54/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 0.9183 - accuracy: 0.7369\n",
            "Epoch 55/100\n",
            "497/497 [==============================] - 54s 109ms/step - loss: 0.8909 - accuracy: 0.7488\n",
            "Epoch 56/100\n",
            "497/497 [==============================] - 54s 108ms/step - loss: 0.8813 - accuracy: 0.7498\n",
            "Epoch 57/100\n",
            "497/497 [==============================] - 54s 108ms/step - loss: 0.8714 - accuracy: 0.7459\n",
            "Epoch 58/100\n",
            "497/497 [==============================] - 53s 108ms/step - loss: 0.8337 - accuracy: 0.7614\n",
            "Epoch 59/100\n",
            "497/497 [==============================] - 53s 108ms/step - loss: 0.8106 - accuracy: 0.7704\n",
            "Epoch 60/100\n",
            "497/497 [==============================] - 53s 108ms/step - loss: 0.8045 - accuracy: 0.7675\n",
            "Epoch 61/100\n",
            "497/497 [==============================] - 54s 109ms/step - loss: 0.8145 - accuracy: 0.7630\n",
            "Epoch 62/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 0.7836 - accuracy: 0.7736\n",
            "Epoch 63/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.7519 - accuracy: 0.7833\n",
            "Epoch 64/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.7752 - accuracy: 0.7766\n",
            "Epoch 65/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 0.7349 - accuracy: 0.7870\n",
            "Epoch 66/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.7365 - accuracy: 0.7856\n",
            "Epoch 67/100\n",
            "497/497 [==============================] - 56s 113ms/step - loss: 0.7495 - accuracy: 0.7753\n",
            "Epoch 68/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.7240 - accuracy: 0.7841\n",
            "Epoch 69/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.7445 - accuracy: 0.7775\n",
            "Epoch 70/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6834 - accuracy: 0.7938\n",
            "Epoch 71/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.7223 - accuracy: 0.7886\n",
            "Epoch 72/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6914 - accuracy: 0.7953\n",
            "Epoch 73/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6905 - accuracy: 0.7957\n",
            "Epoch 74/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6743 - accuracy: 0.7982\n",
            "Epoch 75/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6844 - accuracy: 0.7979\n",
            "Epoch 76/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6808 - accuracy: 0.7949\n",
            "Epoch 77/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6522 - accuracy: 0.8005\n",
            "Epoch 78/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6691 - accuracy: 0.7978\n",
            "Epoch 79/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6751 - accuracy: 0.7983\n",
            "Epoch 80/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6627 - accuracy: 0.8030\n",
            "Epoch 81/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6653 - accuracy: 0.7988\n",
            "Epoch 82/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6345 - accuracy: 0.8052\n",
            "Epoch 83/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6338 - accuracy: 0.8085\n",
            "Epoch 84/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6362 - accuracy: 0.8076\n",
            "Epoch 85/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6410 - accuracy: 0.8015\n",
            "Epoch 86/100\n",
            "497/497 [==============================] - 58s 116ms/step - loss: 0.6398 - accuracy: 0.8053\n",
            "Epoch 87/100\n",
            "497/497 [==============================] - 58s 116ms/step - loss: 0.6419 - accuracy: 0.8029\n",
            "Epoch 88/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.6272 - accuracy: 0.8076\n",
            "Epoch 89/100\n",
            "497/497 [==============================] - 58s 116ms/step - loss: 0.5986 - accuracy: 0.8144\n",
            "Epoch 90/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6226 - accuracy: 0.8075\n",
            "Epoch 91/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6108 - accuracy: 0.8147\n",
            "Epoch 92/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6334 - accuracy: 0.8029\n",
            "Epoch 93/100\n",
            "497/497 [==============================] - 58s 116ms/step - loss: 0.6140 - accuracy: 0.8095\n",
            "Epoch 94/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6053 - accuracy: 0.8175\n",
            "Epoch 95/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.6222 - accuracy: 0.8055\n",
            "Epoch 96/100\n",
            "497/497 [==============================] - 58s 116ms/step - loss: 0.6208 - accuracy: 0.8031\n",
            "Epoch 97/100\n",
            "497/497 [==============================] - 57s 116ms/step - loss: 0.6084 - accuracy: 0.8132\n",
            "Epoch 98/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.5914 - accuracy: 0.8129\n",
            "Epoch 99/100\n",
            "497/497 [==============================] - 57s 115ms/step - loss: 0.5928 - accuracy: 0.8141\n",
            "Epoch 100/100\n",
            "497/497 [==============================] - 57s 114ms/step - loss: 0.5964 - accuracy: 0.8141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5uOCrdP5_l8",
        "outputId": "739b6f90-be3f-49d1-d7b2-215e20d95fde"
      },
      "source": [
        "# Save the weights\n",
        "# model.save_weights('./ldr_lyrics_checkpoint')\n",
        "\n",
        "\n",
        "# Create a new model instance\n",
        "model_loaded = create_model(vocab_size, embed_dim)\n",
        "model_loaded.load_weights('./ldr_lyrics_checkpoint')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5aa269f250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiPyUjHSQlVR"
      },
      "source": [
        "def make_lyrics(model, seed_text, next_words):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list],\n",
        "                     maxlen=max_sequence_len-1,padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWtcy-scQrhI",
        "outputId": "906e7c70-a9b4-4a3c-adf4-32785a7553a0"
      },
      "source": [
        "predicted_lyrics = make_lyrics(model_loaded, 'lolita', 100)\n",
        "print(predicted_lyrics)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lolita hey design single to me to me anyway down in the garden of evil beauty queen of the hollywood sign yeah i also call home when i'm not as rock them all work with to leave my head get crazy in the pale rocky what what what what what all newer can you are who get with you 'round here lately get with you on these beaches got a party we'll dance 'til dawn put you higher and higher and over there out of time past no might not aussi with you used rey just coke it so wow now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYW9z6pjQuUp",
        "outputId": "54236500-26c2-40bd-9290-0be5648de15c"
      },
      "source": [
        "predicted_lyrics = make_lyrics('summer', 100)\n",
        "print(predicted_lyrics)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "summer putting all the lights on and the beautiful people in it verse 1 lana del rey stevie nicks lana del rey stevie nicks carti a cult icys dancer but  del del del rey del del del del rey playboi carti a lights i i i del del del del del del del del del rey hop t t t t tender carti the summer remaining del del del del del del rey del del t nicks lana del rey stevie nicks lana del del del del del del del del del del del del del t del del del del\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BzbVBj3R1pT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}