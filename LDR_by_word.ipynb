{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/czengnn/lana-del-rey-lyrics-generator/blob/main/LDR_by_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZlWo3BTR3CTP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FivZ1COMFE-D",
    "outputId": "c2ff0791-923c-4087-a15a-722749b20961"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load songs\n",
    "songs1 = pd.read_csv('data/lana_lyrics_83.csv').drop('Unnamed: 0', axis=1)\n",
    "songs2 = pd.read_csv('data/lana_lyrics_15.csv').drop('Unnamed: 0', axis=1)\n",
    "songs = pd.concat([songs1, songs2], axis=0)\n",
    "songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D9m7QJNkFIkU"
   },
   "outputs": [],
   "source": [
    "# put lyrics into 1 string\n",
    "text = ''\n",
    "for song in songs['lyrics']:\n",
    "    text = text + song.lower()\n",
    "    \n",
    "# remove the text with brackets around them, such as [Verse 1]\n",
    "text = re.sub(r'\\[[^][]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MesZiJjU3SCh",
    "outputId": "2e8df4f6-198c-41a5-f627-f07cbdb6d1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 161722 characters\n",
      "61 unique characters\n"
     ]
    }
   ],
   "source": [
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "\n",
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AplgShWA3jeS",
    "outputId": "e99f014e-8769-44fc-81ee-09efe8bf672e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why? (\"got that?\")',\n",
       " 'who, me? (\"louder!\")',\n",
       " 'why? (\"got that?\")',\n",
       " \"feet don't fail me now\",\n",
       " 'take me to the finish line',\n",
       " 'oh, my heart, it breaks every step that i take',\n",
       " \"but i'm hoping at the gates, they'll tell me that you're mine\",\n",
       " 'walking through the city streets, is it by mistake or design?',\n",
       " 'i feel so alone on a friday night',\n",
       " \"can you make it feel like home, if i tell you you're mine?\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [line for line in text.split('\\n') if line != '']\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yp--rn6031rr",
    "outputId": "084376af-a731-4640-f4a2-4afa7d85e5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(set(corpus))\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "02Mv1ekh4d41"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Tb0nJE54nbc",
    "outputId": "f3447480-0e7e-4e78-b72b-968ca1025e56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42, 7, 161, 10, 2145, 141, 528],\n",
       " [42, 7, 161, 10, 2145, 141, 528, 17],\n",
       " [42, 7, 161, 10, 2145, 141, 528, 17, 2],\n",
       " [42, 7, 161, 10, 2145, 141, 528, 17, 2, 60],\n",
       " [20, 12],\n",
       " [20, 12, 838],\n",
       " [20, 12, 838, 53],\n",
       " [20, 12, 838, 53, 3],\n",
       " [20, 12, 838, 53, 3, 2096],\n",
       " [20, 12, 838, 53, 3, 2096, 803]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p7r1sw3m40Lp"
   },
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                                         maxlen = max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c6G0ifE5W8-",
    "outputId": "99ae0ca1-499e-4d5c-89f1-4324fecb8437"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 111,  32],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 111,  32,  17]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iJUFvZ3v5jeK"
   },
   "outputs": [],
   "source": [
    "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGniSvLy5pOw"
   },
   "source": [
    "### Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQ9xj1TQ5mYs",
    "outputId": "46dcb2de-9ef9-4f77-8d59-9169346a5794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 04:13:43.188 tensorflow-2-3-cpu-py-ml-m5-xlarge-d436dc423c77fbec5bea3834b1e4:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-05-12 04:13:43.329 tensorflow-2-3-cpu-py-ml-m5-xlarge-d436dc423c77fbec5bea3834b1e4:25 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 17, 50)            128750    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 17, 300)           241200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 17, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1287)              129987    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2575)              3316600   \n",
      "=================================================================\n",
      "Total params: 3,976,937\n",
      "Trainable params: 3,976,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "vocab_size = total_words\n",
    "embed_dim = 50\n",
    "def create_model(vocab_size, embed_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim, input_length=max_sequence_len-1))\n",
    "    # Add an LSTM Layer\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "    # A dropout layer for regularisation\n",
    "    model.add(Dropout(0.2))\n",
    "    # Add another LSTM Layer\n",
    "    model.add(LSTM(100,return_sequences=False)) \n",
    "    model.add(Dense(vocab_size//2, activation='relu'))\n",
    "    # In the last layer, the shape should be equal to the total number of words present in our corpus\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss=sparse_cat_loss, optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
    "    return model\n",
    "\n",
    "model = create_model(vocab_size, embed_dim)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUS1h2h_53su",
    "outputId": "58b0d40b-8752-42b9-d1f8-38d4131a59c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "137/865 [===>..........................] - ETA: 43s - loss: 7.8321 - accuracy: 0.0365"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "epochs = 100\n",
    "history = model.fit(predictors, label, epochs=epochs, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights('models/ldr_by_word/ldr_by_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJyf8E37KgMc",
    "outputId": "837394b3-b9e3-4243-d5a9-ea49550ca779"
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "IBujCyBwKmzo",
    "outputId": "7e99d427-b168-4f0d-9b4a-cc2d536e4f1f"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.title('loss & accuracy')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9zC0bv4P41P"
   },
   "source": [
    "#### Recreate the model and load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5uOCrdP5_l8",
    "outputId": "e4f17d47-aa7e-49d5-e92c-f7427ab279f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f93aa7e2050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model_loaded = create_model(vocab_size, embed_dim)\n",
    "model_loaded.load_weights('models/ldr_by_word/ldr_by_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OiPyUjHSQlVR"
   },
   "outputs": [],
   "source": [
    "def make_lyrics(model, seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list],\n",
    "                     maxlen=max_sequence_len-1,padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWtcy-scQrhI",
    "outputId": "c9f0f328-2cf5-4ec4-dceb-d1c7f8140a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lolita seems diddy sweatshirt sweatshirt pain age age seems mustang mustang chaos dining crowns anywhere crowns crowns clear there's thrills national upper snow smiling smiling for… till drag baking baking believe believe he's he's he's he's he's he's he's he's headshot headshot headshot headshot headshot headshot headshot headshot headshot headshot tryna tryna honestly crowns doll doll doll doll headshot threshold butterflies blurring dear truck line line commitment god free till began livin's teeth began teeth began teeth charge teeth a charge stopped stopped clear backseat clear backseat glow glow ciao ciao baking baking baking clear paved are are sweatshirt understand understand\n"
     ]
    }
   ],
   "source": [
    "predicted_lyrics = make_lyrics(model, 'lolita', 100)\n",
    "print(predicted_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcrMbyOMIfLs",
    "outputId": "5acd66c3-9582-4a96-de38-aa9d0bd86c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lolita to it's coast but do all it thing better what the walls at doop you take you da huh off he my ride god 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause 'cause\n"
     ]
    }
   ],
   "source": [
    "predicted_lyrics = make_lyrics(model_loaded, 'lolita', 100)\n",
    "print(predicted_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYW9z6pjQuUp",
    "outputId": "82d7f2e8-de3d-4bed-aadb-4006d11ba67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby blue tired lived time and i'm my jam out girl the cry now be top make lookin' summer's soundin' tropic up dream get and to the have you the stronger da anywhere they'll on of nothin' all a soft powerful in a friend in lot gunnin' girl to scene we and then to see you have back mine is love when do up his you song i want is so me wha soul run get i just— patio light follow or to scene is stay it pearls them 'til do do do do do do do do the die me it's\n"
     ]
    }
   ],
   "source": [
    "predicted_lyrics = make_lyrics(model_loaded, 'baby blue', 100)\n",
    "print(predicted_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBhQMXoDGENl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5lIg5tv8Vz09gQDzHNgUL",
   "include_colab_link": true,
   "mount_file_id": "1wyacN2Z1_YP6yW7MyXJHLxpMK7D1vPrh",
   "name": "LDR_by_word.ipynb",
   "provenance": []
  },
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
