{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDR_by_word.ipynb",
      "provenance": [],
      "mount_file_id": "1wyacN2Z1_YP6yW7MyXJHLxpMK7D1vPrh",
      "authorship_tag": "ABX9TyO5lIg5tv8Vz09gQDzHNgUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czengnn/lana-del-rey-lyrics-generator/blob/main/LDR_by_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlWo3BTR3CTP"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import re \n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FivZ1COMFE-D",
        "outputId": "c2ff0791-923c-4087-a15a-722749b20961"
      },
      "source": [
        "# load songs\n",
        "songs1 = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_83.csv').drop('Unnamed: 0', axis=1)\n",
        "songs2 = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_15.csv').drop('Unnamed: 0', axis=1)\n",
        "songs = pd.concat([songs1, songs2], axis=0)\n",
        "songs.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9m7QJNkFIkU"
      },
      "source": [
        "# put lyrics into 1 string\n",
        "text = ''\n",
        "for song in songs['lyrics']:\n",
        "    text = text + song.lower()\n",
        "    \n",
        "# remove the text with brackets around them, such as [Verse 1]\n",
        "text = re.sub(r'\\[[^][]*\\]', '', text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MesZiJjU3SCh",
        "outputId": "2e8df4f6-198c-41a5-f627-f07cbdb6d1ee"
      },
      "source": [
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 161722 characters\n",
            "61 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AplgShWA3jeS",
        "outputId": "e99f014e-8769-44fc-81ee-09efe8bf672e"
      },
      "source": [
        "corpus = [line for line in text.split('\\n') if line != '']\n",
        "corpus[:10]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['why? (\"got that?\")',\n",
              " 'who, me? (\"louder!\")',\n",
              " 'why? (\"got that?\")',\n",
              " \"feet don't fail me now\",\n",
              " 'take me to the finish line',\n",
              " 'oh, my heart, it breaks every step that i take',\n",
              " \"but i'm hoping at the gates, they'll tell me that you're mine\",\n",
              " 'walking through the city streets, is it by mistake or design?',\n",
              " 'i feel so alone on a friday night',\n",
              " \"can you make it feel like home, if i tell you you're mine?\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp--rn6031rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084376af-a731-4640-f4a2-4afa7d85e5ad"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(set(corpus))\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Mv1ekh4d41"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tb0nJE54nbc",
        "outputId": "f3447480-0e7e-4e78-b72b-968ca1025e56"
      },
      "source": [
        "input_sequences[20:30]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[28, 8, 158, 10, 1247, 145, 602],\n",
              " [28, 8, 158, 10, 1247, 145, 602, 17],\n",
              " [28, 8, 158, 10, 1247, 145, 602, 17, 3],\n",
              " [28, 8, 158, 10, 1247, 145, 602, 17, 3, 49],\n",
              " [27, 11],\n",
              " [27, 11, 808],\n",
              " [27, 11, 808, 55],\n",
              " [27, 11, 808, 55, 2],\n",
              " [27, 11, 808, 55, 2, 1248],\n",
              " [27, 11, 808, 55, 2, 1248, 603]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7r1sw3m40Lp"
      },
      "source": [
        "# pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences,\n",
        "                                         maxlen = max_sequence_len, padding='pre'))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c6G0ifE5W8-",
        "outputId": "99ae0ca1-499e-4d5c-89f1-4324fecb8437"
      },
      "source": [
        "input_sequences[:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 105,  33],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 105,  33,  17],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  81,   4],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  81,   4, 213],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 105,  33]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJUFvZ3v5jeK"
      },
      "source": [
        "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGniSvLy5pOw"
      },
      "source": [
        "### Building The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ9xj1TQ5mYs",
        "outputId": "46dcb2de-9ef9-4f77-8d59-9169346a5794"
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n",
        "vocab_size = total_words\n",
        "embed_dim = 50\n",
        "def create_model(vocab_size, embed_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim, input_length=max_sequence_len-1))\n",
        "    # Add an LSTM Layer\n",
        "    model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "    # A dropout layer for regularisation\n",
        "    model.add(Dropout(0.2))\n",
        "    # Add another LSTM Layer\n",
        "    model.add(LSTM(100,return_sequences=False)) \n",
        "    model.add(Dense(vocab_size//2, activation='relu'))\n",
        "    # In the last layer, the shape should be equal to the total number of words present in our corpus\n",
        "    model.add(Dense(vocab_size, activation='softmax'))\n",
        "    model.compile(loss=sparse_cat_loss, optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
        "    return model\n",
        "\n",
        "model = create_model(vocab_size, embed_dim)\n",
        "print(model.summary())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 17, 50)            128750    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 17, 300)           241200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1287)              129987    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2575)              3316600   \n",
            "=================================================================\n",
            "Total params: 3,976,937\n",
            "Trainable params: 3,976,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUS1h2h_53su",
        "outputId": "58b0d40b-8752-42b9-d1f8-38d4131a59c8"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "history = model.fit(predictors, label, epochs=100, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "# Save the weights\n",
        "model.save_weights('/content/drive/MyDrive/data/models/ldr_by_word/ldr_by_word')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 6.0795 - accuracy: 0.0381\n",
            "Epoch 2/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 5.4864 - accuracy: 0.0700\n",
            "Epoch 3/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 5.1083 - accuracy: 0.0975\n",
            "Epoch 4/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 4.8111 - accuracy: 0.1181\n",
            "Epoch 5/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 4.5322 - accuracy: 0.1481\n",
            "Epoch 6/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 4.2546 - accuracy: 0.1751\n",
            "Epoch 7/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 3.9658 - accuracy: 0.2068\n",
            "Epoch 8/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 3.6876 - accuracy: 0.2395\n",
            "Epoch 9/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 3.4110 - accuracy: 0.2762\n",
            "Epoch 10/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 3.1456 - accuracy: 0.3129\n",
            "Epoch 11/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 2.8871 - accuracy: 0.3501\n",
            "Epoch 12/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 2.6562 - accuracy: 0.3915\n",
            "Epoch 13/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 2.4442 - accuracy: 0.4244\n",
            "Epoch 14/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 2.2465 - accuracy: 0.4610\n",
            "Epoch 15/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 2.0814 - accuracy: 0.4900\n",
            "Epoch 16/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 1.9215 - accuracy: 0.5207\n",
            "Epoch 17/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 1.7823 - accuracy: 0.5494\n",
            "Epoch 18/100\n",
            "865/865 [==============================] - 102s 117ms/step - loss: 1.6538 - accuracy: 0.5742\n",
            "Epoch 19/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 1.5389 - accuracy: 0.5982\n",
            "Epoch 20/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 1.4311 - accuracy: 0.6205\n",
            "Epoch 21/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 1.3498 - accuracy: 0.6404\n",
            "Epoch 22/100\n",
            "865/865 [==============================] - 102s 117ms/step - loss: 1.2648 - accuracy: 0.6619\n",
            "Epoch 23/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 1.1871 - accuracy: 0.6758\n",
            "Epoch 24/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 1.1281 - accuracy: 0.6898\n",
            "Epoch 25/100\n",
            "865/865 [==============================] - 100s 116ms/step - loss: 1.0817 - accuracy: 0.7019\n",
            "Epoch 26/100\n",
            "865/865 [==============================] - 101s 116ms/step - loss: 1.0189 - accuracy: 0.7181\n",
            "Epoch 27/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 0.9712 - accuracy: 0.7288\n",
            "Epoch 28/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.9437 - accuracy: 0.7328\n",
            "Epoch 29/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.9129 - accuracy: 0.7420\n",
            "Epoch 30/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.8710 - accuracy: 0.7528\n",
            "Epoch 31/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.8464 - accuracy: 0.7593\n",
            "Epoch 32/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.8257 - accuracy: 0.7637\n",
            "Epoch 33/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.8004 - accuracy: 0.7701\n",
            "Epoch 34/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.7969 - accuracy: 0.7704\n",
            "Epoch 35/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.7597 - accuracy: 0.7825\n",
            "Epoch 36/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 0.7496 - accuracy: 0.7836\n",
            "Epoch 37/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 0.7443 - accuracy: 0.7853\n",
            "Epoch 38/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 0.7206 - accuracy: 0.7894\n",
            "Epoch 39/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.7119 - accuracy: 0.7928\n",
            "Epoch 40/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 0.7030 - accuracy: 0.7940\n",
            "Epoch 41/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6908 - accuracy: 0.7991\n",
            "Epoch 42/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6856 - accuracy: 0.7979\n",
            "Epoch 43/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6717 - accuracy: 0.8036\n",
            "Epoch 44/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.6685 - accuracy: 0.8039\n",
            "Epoch 45/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.6633 - accuracy: 0.8047\n",
            "Epoch 46/100\n",
            "865/865 [==============================] - 102s 117ms/step - loss: 0.6611 - accuracy: 0.8057\n",
            "Epoch 47/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6432 - accuracy: 0.8078\n",
            "Epoch 48/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6459 - accuracy: 0.8067\n",
            "Epoch 49/100\n",
            "865/865 [==============================] - 98s 114ms/step - loss: 0.6426 - accuracy: 0.8103\n",
            "Epoch 50/100\n",
            "865/865 [==============================] - 96s 111ms/step - loss: 0.6368 - accuracy: 0.8089\n",
            "Epoch 51/100\n",
            "865/865 [==============================] - 97s 112ms/step - loss: 0.6248 - accuracy: 0.8129\n",
            "Epoch 52/100\n",
            "865/865 [==============================] - 100s 115ms/step - loss: 0.6327 - accuracy: 0.8112\n",
            "Epoch 53/100\n",
            "865/865 [==============================] - 99s 115ms/step - loss: 0.6209 - accuracy: 0.8132\n",
            "Epoch 54/100\n",
            "865/865 [==============================] - 96s 111ms/step - loss: 0.6196 - accuracy: 0.8130\n",
            "Epoch 55/100\n",
            "865/865 [==============================] - 95s 110ms/step - loss: 0.6197 - accuracy: 0.8132\n",
            "Epoch 56/100\n",
            "865/865 [==============================] - 98s 113ms/step - loss: 0.6099 - accuracy: 0.8158\n",
            "Epoch 57/100\n",
            "865/865 [==============================] - 97s 112ms/step - loss: 0.6077 - accuracy: 0.8148\n",
            "Epoch 58/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6070 - accuracy: 0.8162\n",
            "Epoch 59/100\n",
            "865/865 [==============================] - 101s 117ms/step - loss: 0.6135 - accuracy: 0.8144\n",
            "Epoch 60/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.6029 - accuracy: 0.8160\n",
            "Epoch 61/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5939 - accuracy: 0.8181\n",
            "Epoch 62/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5884 - accuracy: 0.8202\n",
            "Epoch 63/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5859 - accuracy: 0.8196\n",
            "Epoch 64/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5929 - accuracy: 0.8182\n",
            "Epoch 65/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5879 - accuracy: 0.8187\n",
            "Epoch 66/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5899 - accuracy: 0.8191\n",
            "Epoch 67/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5858 - accuracy: 0.8203\n",
            "Epoch 68/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5775 - accuracy: 0.8206\n",
            "Epoch 69/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5827 - accuracy: 0.8196\n",
            "Epoch 70/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5744 - accuracy: 0.8224\n",
            "Epoch 71/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5728 - accuracy: 0.8224\n",
            "Epoch 72/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5672 - accuracy: 0.8226\n",
            "Epoch 73/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5752 - accuracy: 0.8222\n",
            "Epoch 74/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5719 - accuracy: 0.8220\n",
            "Epoch 75/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5725 - accuracy: 0.8200\n",
            "Epoch 76/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5686 - accuracy: 0.8228\n",
            "Epoch 77/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5623 - accuracy: 0.8224\n",
            "Epoch 78/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5665 - accuracy: 0.8219\n",
            "Epoch 79/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5610 - accuracy: 0.8246\n",
            "Epoch 80/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5585 - accuracy: 0.8253\n",
            "Epoch 81/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5611 - accuracy: 0.8230\n",
            "Epoch 82/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5578 - accuracy: 0.8251\n",
            "Epoch 83/100\n",
            "865/865 [==============================] - 103s 118ms/step - loss: 0.5577 - accuracy: 0.8250\n",
            "Epoch 84/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5588 - accuracy: 0.8243\n",
            "Epoch 85/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5483 - accuracy: 0.8270\n",
            "Epoch 86/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5524 - accuracy: 0.8263\n",
            "Epoch 87/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5542 - accuracy: 0.8242\n",
            "Epoch 88/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5545 - accuracy: 0.8237\n",
            "Epoch 89/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5576 - accuracy: 0.8254\n",
            "Epoch 90/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5480 - accuracy: 0.8245\n",
            "Epoch 91/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5482 - accuracy: 0.8272\n",
            "Epoch 92/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5540 - accuracy: 0.8260\n",
            "Epoch 93/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5488 - accuracy: 0.8253\n",
            "Epoch 94/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5436 - accuracy: 0.8278\n",
            "Epoch 95/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5447 - accuracy: 0.8264\n",
            "Epoch 96/100\n",
            "865/865 [==============================] - 103s 119ms/step - loss: 0.5368 - accuracy: 0.8293\n",
            "Epoch 97/100\n",
            "865/865 [==============================] - 102s 118ms/step - loss: 0.5477 - accuracy: 0.8265\n",
            "Epoch 98/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5387 - accuracy: 0.8270\n",
            "Epoch 99/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5497 - accuracy: 0.8254\n",
            "Epoch 100/100\n",
            "865/865 [==============================] - 104s 120ms/step - loss: 0.5410 - accuracy: 0.8274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJyf8E37KgMc",
        "outputId": "837394b3-b9e3-4243-d5a9-ea49550ca779"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IBujCyBwKmzo",
        "outputId": "7e99d427-b168-4f0d-9b4a-cc2d536e4f1f"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.title('loss & accuracy')\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9zC0bv4P41P"
      },
      "source": [
        "#### Recreate the model and load saved weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5uOCrdP5_l8",
        "outputId": "e4f17d47-aa7e-49d5-e92c-f7427ab279f9"
      },
      "source": [
        "# Create a new model instance\n",
        "model_loaded = create_model(vocab_size, embed_dim)\n",
        "model_loaded.load_weights('/content/drive/MyDrive/data/models/ldr_by_word/ldr_by_word')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5a1fb802d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiPyUjHSQlVR"
      },
      "source": [
        "def make_lyrics(model, seed_text, next_words):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list],\n",
        "                     maxlen=max_sequence_len-1,padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWtcy-scQrhI",
        "outputId": "c9f0f328-2cf5-4ec4-dceb-d1c7f8140a9a"
      },
      "source": [
        "predicted_lyrics = make_lyrics(model, 'lolita', 100)\n",
        "print(predicted_lyrics)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lolita bitch lookin' at me like a magazine wearing romeo there on the city of miami fun and god i loved to sing what i need you i'd never leave you now i'm hearing arrived then we dance on that night there just swallow some wine i can change that night only mine too light as that old jukebox what your lipstick on the tour of his cocaine heart if you cigar ready on the poems we burned for sure real you got a war in my mind with you daddy hey la princesa poet resident laurel fun so light everybody\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcrMbyOMIfLs",
        "outputId": "5acd66c3-9582-4a96-de38-aa9d0bd86c4e"
      },
      "source": [
        "predicted_lyrics = make_lyrics(model_loaded, 'lolita', 100)\n",
        "print(predicted_lyrics)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lolita writing guitar remember me i nevada but just that just yeah fell just but for hurt hurt hurt hurt hurt hurt hurt hurt hurt hurt hurt hurt hurt hurt hurt just yeah just yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah just just just yeah just yeah just yeah just yeah just yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYW9z6pjQuUp",
        "outputId": "82d7f2e8-de3d-4bed-aadb-4006d11ba67c"
      },
      "source": [
        "predicted_lyrics = make_lyrics(model_loaded, 'baby blue', 100)\n",
        "print(predicted_lyrics)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baby blue electric buy time and i'm my sends out away the mine now be remember go suit clothes sparkle blond got myself know and to the say you the rage da killing aeroplane on of deep all a catch fail in a war in soul odds away to reasons we and then to let you say back cry is love when do got put you around i have is so me famous some light know i darts jam world baby's were to reasons is stay it fiends fire two do do do do do do do do the eyes me it's\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBhQMXoDGENl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}