{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDR.ipynb",
      "provenance": [],
      "mount_file_id": "1YsCFde9O7H5v6sAu9Eu1oIdFbLEoiMel",
      "authorship_tag": "ABX9TyP23bfkDOM4YvwJ/KhFVJXk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czengnn/lana-del-rey-lyrics-generator/blob/main/LDR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffVU7m5uq9cW"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import re \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neEO7YMGrLXH"
      },
      "source": [
        "# load songs\n",
        "songs = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_83.csv').drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# get rid of parts of text that are like: [Intro: Lana Del Rey + sample], [Pre-Chorus]\n",
        "songs['lyrics'] = songs['lyrics'].apply(lambda s: re.sub('\\[[^][]*\\]', '', s))\n",
        "\n",
        "# put lyrics into 1 string\n",
        "text = ''\n",
        "for song in songs['lyrics']:\n",
        "  text = text + song.lower()\n",
        "\n",
        "# Save Lyrics in .txt file\n",
        "with open('lyricsText.txt', 'w',encoding=\"utf-8\") as filehandle:  \n",
        "    for song in songs['lyrics']:\n",
        "        filehandle.write('%s\\n' % song.lower())"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUQrFdYC2hNo",
        "outputId": "feeabbe1-0c4e-408d-96f7-bc63f25c2387"
      },
      "source": [
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 135928 characters\n",
            "58 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP0meFb05Bq5",
        "outputId": "10b10af4-367c-43bf-b3d8-949b5a5c894a"
      },
      "source": [
        "# taking a look at the first 300 characters\n",
        "print(text[:300])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "why? (\"got that?\")\n",
            "who, me? (\"louder!\")\n",
            "why? (\"got that?\")\n",
            "\n",
            "\n",
            "feet don't fail me now\n",
            "take me to the finish line\n",
            "oh, my heart, it breaks every step that i take\n",
            "but i'm hoping at the gates, they'll tell me that you're mine\n",
            "walking through the city streets, is it by mistake or design?\n",
            "i feel so alone o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqyY7TxY7lp8",
        "outputId": "b3d58f39-e66b-4a7f-bfb6-c04ac4412b16"
      },
      "source": [
        "example_texts = ['fail', 'me', 'now']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'f', b'a', b'i', b'l'], [b'm', b'e'], [b'n', b'o', b'w']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMFAEfC_3z2S"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW--OpgY7xmn",
        "outputId": "69f2fe60-77bb-4cb1-cf9b-1e19af58def4"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[28, 23, 31, 34], [35, 27], [36, 37, 45]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_i_LnId6lF8"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9QrppvF6wbP",
        "outputId": "b1cb78ae-9793-44e6-a9ab-eed08c6a5607"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'f', b'a', b'i', b'l'], [b'm', b'e'], [b'n', b'o', b'w']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6b_9Lg873WN"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IF5RcM38CoM",
        "outputId": "f74343cc-2542-40dd-8963-2f81668a951d"
      },
      "source": [
        "text_from_ids(ids)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'fail', b'me', b'now'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL66NPny8EJo",
        "outputId": "bd89a98c-5c78-409c-e7d8-3348afc89d3b"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(135928,), dtype=int64, numpy=array([ 2, 45, 30, ..., 23, 24, 47])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-_HYg4l8Lpc"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTKTtA738Nqe",
        "outputId": "13c62a43-06a7-4fae-b4cf-d7ed549a7b5f"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "w\n",
            "h\n",
            "y\n",
            "?\n",
            " \n",
            "(\n",
            "\"\n",
            "g\n",
            "o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EECzBxk98Q2o"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey1-ceNp8Ti9",
        "outputId": "874de050-a6ad-4182-c335-f8d64505253c"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\nwhy? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the f'\n",
            "b\"inish line\\noh, my heart, it breaks every step that i take\\nbut i'm hoping at the gates, they'll tell m\"\n",
            "b\"e that you're mine\\nwalking through the city streets, is it by mistake or design?\\ni feel so alone on a\"\n",
            "b\" friday night\\ncan you make it feel like home, if i tell you you're mine?\\nit's like i told you, honey \"\n",
            "b'(\"louder!\")\\n\\n\\ndon\\'t make me sad, don\\'t make me cry\\nsometimes love is not enough and the road gets tou'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db_YzW048U9X"
      },
      "source": [
        "# takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpfzNk7t8fdQ"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boaQQFlF-mm2",
        "outputId": "0e226142-3ee9-4dba-88a2-ec815bed5d4f"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'\\nwhy? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the '\n",
            "Target: b'why? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the f'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz518isD-3H0"
      },
      "source": [
        "### Create Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbH-lqAO-m5o",
        "outputId": "9c1c19e8-73aa-47c7-e9a8-12eb97c28eda"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVW3E2r8-_J4"
      },
      "source": [
        "### Building The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik8OAew7-2Yn"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCWSc8Xo_Eyf"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ZFpS0S_G3W"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2yf_n8e_Li8"
      },
      "source": [
        "### Trying the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTk2znIp_IIf",
        "outputId": "ed2f2595-973a-4f77-b722-9f6ae900b7b8"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 60) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytzAe4X4_NeE",
        "outputId": "1063810f-ca9d-4897-f975-5472d7f054bf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  15360     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  61500     \n",
            "=================================================================\n",
            "Total params: 4,015,164\n",
            "Trainable params: 4,015,164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLGahEeO_Pbp"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbtgRahv_S1l",
        "outputId": "e9b89701-9b52-4c4f-f50f-aed82e204397"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 13, 29, 19, 48, 47,  8, 21, 48, 42, 42, 36, 40, 37, 56, 25, 34,\n",
              "       41, 56, 54, 17, 55, 43,  8, 19, 16, 19, 11, 48, 19, 36, 16, 14, 41,\n",
              "       51, 50, 32, 46, 11, 47, 43, 45, 49, 13,  5, 40, 15, 58, 47, 53, 45,\n",
              "       20, 26, 55, 47, 36, 43, 19,  3, 53, 32, 59, 46, 30, 28, 45,  8,  8,\n",
              "        3, 47, 30,  9, 27, 56, 33, 29,  0, 20, 36, 34, 40, 50, 25, 53, 22,\n",
              "       19, 46, 17, 18,  8, 48, 12, 54,  9, 38,  5, 11, 40, 34, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osaXFwDd_XHU",
        "outputId": "bd8f199b-6864-468e-99cb-eae55a1dea57"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'gold\\nand i was like...\\n\\n\\ntake off, take off, take off all your clothes\\ntake off, take off, take off '\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\n0g7zy);zttnro\\xe2\\x80\\x99cls\\xe2\\x80\\x99\\xe2\\x80\\x8b5\\xe2\\x80\\x94u)747.z7n41s\\xc3\\xb3\\xc3\\xb1jx.yuw\\xc3\\xad0\"r2\\xe2\\x80\\xa6y\\xe2\\x80\\x8aw9d\\xe2\\x80\\x94ynu7 \\xe2\\x80\\x8aj\\xef\\xbb\\xbfxhfw)) yh,e\\xe2\\x80\\x99kg9nlr\\xc3\\xb1c\\xe2\\x80\\x8a?7x56)z/\\xe2\\x80\\x8b,p\".rll'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNmbZtz__Y63"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}