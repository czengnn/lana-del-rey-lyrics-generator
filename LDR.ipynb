{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YsCFde9O7H5v6sAu9Eu1oIdFbLEoiMel",
      "authorship_tag": "ABX9TyOKCIC4Ew4KVUEEAyTjRA4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czengnn/lana-del-rey-lyrics-generator/blob/main/LDR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffVU7m5uq9cW"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import re \n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neEO7YMGrLXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f7dd5f-2710-4a72-d557-5405c758566c"
      },
      "source": [
        "# load songs\n",
        "songs1 = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_83.csv').drop('Unnamed: 0', axis=1)\n",
        "songs2 = pd.read_csv('/content/drive/MyDrive/data/lana_lyrics_15.csv').drop('Unnamed: 0', axis=1)\n",
        "songs = pd.concat([songs1, songs2], axis=0)\n",
        "songs.shape"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzGQ7sSrgo5",
        "outputId": "f79fda85-9c60-4d71-d813-4d3bc91faaf0"
      },
      "source": [
        "# test revoming text with brackets around them\n",
        "test_text = songs2.lyrics[0][:50]\n",
        "print(test_text)\n",
        "print(re.sub(r'\\[[^][]*\\]', '', test_text))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Verse 1]\n",
            "Sun stare, don't care with my head in my\n",
            "\n",
            "Sun stare, don't care with my head in my\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Dwmg6gq4mT"
      },
      "source": [
        "# put lyrics into 1 string\n",
        "text = ''\n",
        "for song in songs['lyrics']:\n",
        "    text = text + song.lower()\n",
        "# remove the text with brackets around them, such as [Verse 1]\n",
        "text = re.sub(r'\\[[^][]*\\]', '', text)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUQrFdYC2hNo",
        "outputId": "b25dd3d7-c34d-45c1-d68a-1cfda473285e"
      },
      "source": [
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 161722 characters\n",
            "61 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP0meFb05Bq5",
        "outputId": "3a2cc4b0-ec47-4dcd-b0e2-ae81c80f95a7"
      },
      "source": [
        "# taking a look at the first 300 characters\n",
        "print(text[:300])"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "why? (\"got that?\")\n",
            "who, me? (\"louder!\")\n",
            "why? (\"got that?\")\n",
            "\n",
            "\n",
            "feet don't fail me now\n",
            "take me to the finish line\n",
            "oh, my heart, it breaks every step that i take\n",
            "but i'm hoping at the gates, they'll tell me that you're mine\n",
            "walking through the city streets, is it by mistake or design?\n",
            "i feel so alone o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMFAEfC_3z2S"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab))\n",
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True)\n",
        "\n",
        "# join the characters back into strings\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir9bvs-Ar391",
        "outputId": "715843c2-25bf-465a-c151-5f6074fa1a61"
      },
      "source": [
        "# Create training examples and targets\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(161722,), dtype=int64, numpy=array([ 2, 45, 30, ..., 37, 44, 27])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdk6Vgw6s64W"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLS3KIv5s9_f"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59VB-A_Ks99D",
        "outputId": "7398905d-3f18-4b21-957b-86b70335e003"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\nwhy? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the f'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nyLBiBbs96e"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtD4OyiIs939",
        "outputId": "78aa16f4-d3a1-4767-a26d-0c005614ca75"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auxaRHL9s91R",
        "outputId": "d2ba9b66-0a53-43e0-cf89-a4782261b50f"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'\\nwhy? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the '\n",
            "Target: b'why? (\"got that?\")\\nwho, me? (\"louder!\")\\nwhy? (\"got that?\")\\n\\n\\nfeet don\\'t fail me now\\ntake me to the f'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaRCG0iJtSSM"
      },
      "source": [
        "### Create training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOLJ01y5s9yx",
        "outputId": "3a93495f-3622-46a5-f175-1c69a27f350d"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlSLRqFHtYTp"
      },
      "source": [
        "### Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaM_TY9Ks9t2"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 512"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ARhng_zu32M"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = Embedding(vocab_size, #61\n",
        "                                   embedding_dim, #256\n",
        "                                   batch_input_shape=[BATCH_SIZE, None]) #64\n",
        "        self.LSTM_1 = Bidirectional(LSTM(rnn_units, #512\n",
        "                           return_sequences=True,\n",
        "                           stateful=True))\n",
        "        self.Dropout_1 = Dropout(0.2)        \n",
        "        self.LSTM_2 = LSTM(rnn_units, #512\n",
        "                           return_sequences=True, \n",
        "                           stateful=True)\n",
        "        self.Dropout_2 = Dropout(0.2) \n",
        "        self.dense_1 = Dense(vocab_size/2, activation='relu')\n",
        "        self.dense_2 = Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        x = self.LSTM_1(x, training=training)\n",
        "        x = self.Dropout_1(x, training=training)\n",
        "        x = self.LSTM_2(x, training=training)\n",
        "        x = self.Dropout_2(x, training=training)\n",
        "        x = self.dense_1(x, training=training)\n",
        "        x = self.dense_2(x, training=training)\n",
        "        return x\n",
        "# ValueError: Input 0 is incompatible with layer forward_lstm_51: \n",
        "# expected shape=(64, None, 256), found shape=(1, None, 256)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhEkSGMho1i8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJL6aJrBn7Dw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uSjmyuYtbNK"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as4pGyTTndqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig1YIARItbKV",
        "outputId": "e94efc08-ec07-43a9-861b-9a0f440e5158"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 63) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dig380GBtbH7",
        "outputId": "99499e5c-b706-4a01-fc70-6a603ba95d3c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     multiple                  16128     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection multiple                  3149824   \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "lstm_52 (LSTM)               multiple                  3147776   \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             multiple                  15903     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             multiple                  2016      \n",
            "=================================================================\n",
            "Total params: 6,331,647\n",
            "Trainable params: 6,331,647\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YTzIvLMFHur"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbkrrgOltbFW"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgpKZmNtbCs",
        "outputId": "09e63c47-2cba-4d9f-e7fa-647eaf313fb9"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(dataset, \n",
        "                    epochs=EPOCHS, \n",
        "                    callbacks=[early_stopping])\n",
        "model.save(\"/content/drive/MyDrive/data/models/LDR_tf_model\")"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 224s 9s/step - loss: 0.1011\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 223s 9s/step - loss: 0.0963\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 222s 9s/step - loss: 0.0932\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 223s 9s/step - loss: 0.0903\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 222s 9s/step - loss: 0.0862\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 219s 9s/step - loss: 0.0852\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 216s 9s/step - loss: 0.0813\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 217s 9s/step - loss: 0.0790\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 216s 9s/step - loss: 0.0764\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 217s 9s/step - loss: 0.0746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_58_layer_call_and_return_conditional_losses, lstm_cell_58_layer_call_fn, lstm_cell_56_layer_call_and_return_conditional_losses, lstm_cell_56_layer_call_fn, lstm_cell_57_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_58_layer_call_and_return_conditional_losses, lstm_cell_58_layer_call_fn, lstm_cell_56_layer_call_and_return_conditional_losses, lstm_cell_56_layer_call_fn, lstm_cell_57_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/data/models/LDR_tf_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/data/models/LDR_tf_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKedZbWGUPPU",
        "outputId": "70911751-a298-4c43-a7ae-bceedc3e8b5a"
      },
      "source": [
        "# history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sSpK-n2nTUpI",
        "outputId": "053c39ed-9245-4094-c2cc-4f45aa9bf14b"
      },
      "source": [
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra9O9qrKlLMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ymNiDrXkM4k"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBclSLlbVnH1"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    # skip_ids = self.ids_from_chars(['', '[UNK]'])[:, None]\n",
        "    # sparse_mask = tf.SparseTensor(\n",
        "    #     # Put a -inf at each bad index.\n",
        "    #     values=[-float('inf')]*len(skip_ids),\n",
        "    #     indices=skip_ids,\n",
        "    #     # Match the shape to the vocabulary\n",
        "    #     dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    # self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hK9QUQWEaz"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "76jmkfxSWhtx",
        "outputId": "b847fb89-da13-4887-c55f-04bd5a9e30b9"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['james dean'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-226-d87138131442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3885\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-220-d913d7ef3d91>:27 generate_one_step  *\n        predicted_logits, states = self.model(inputs=input_ids, states=states,\n    <ipython-input-170-b65435476abe>:21 call  *\n        x = self.LSTM_1(x, training=training)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:539 __call__  **\n        return super(Bidirectional, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:653 call\n        initial_state=forward_state, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer forward_lstm_51: expected shape=(64, None, 256), found shape=(1, None, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRsYttUeVJ07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}